{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"Custom_location_53_345035_-6_267261_62b5c8e6c91d98000ba01ceb.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop sea_level, city_name, grnd_level, wind_gust, rain_1h, rain_3h, snow_1h, snow_3h\n",
    "data.drop(columns=[\"city_name\", \"sea_level\", \"grnd_level\", \"wind_gust\", \"rain_1h\", \"rain_3h\", \"snow_1h\", \"snow_3h\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Rain': 0, 'Clouds': 1, 'Mist': 2, 'Drizzle': 3, 'Snow': 4, 'Clear': 5, 'Fog': 6, 'Thunderstorm': 7, 'Smoke': 8, 'Haze': 9}\n"
     ]
    }
   ],
   "source": [
    "# transfer weather_main\n",
    "# {'Rain': 0, 'Clouds': 1, 'Mist': 2, 'Drizzle': 3, 'Snow': 4, \n",
    "# 'Clear': 5, 'Fog': 6, 'Thunderstorm': 7, 'Smoke': 8, 'Haze': 9}\n",
    "weather_main_unique = list(data[\"weather_main\"].unique())\n",
    "weather_main_map = dict()\n",
    "for i in range(len(weather_main_unique)):\n",
    "    weather_main_map[weather_main_unique[i]] = i\n",
    "print(weather_main_map)\n",
    "keys = []\n",
    "vals = []\n",
    "for key, val in weather_main_map.items():\n",
    "    keys.append(key)\n",
    "    vals.append(val)\n",
    "data[\"weather_main\"] = data[\"weather_main\"].replace(keys, vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'moderate rain': 0, 'light rain': 1, 'broken clouds': 2, 'scattered clouds': 3, 'few clouds': 4, 'light intensity shower rain': 5, 'mist': 6, 'light intensity drizzle': 7, 'overcast clouds': 8, 'light intensity drizzle rain': 9, 'light shower snow': 10, 'sky is clear': 11, 'fog': 12, 'light shower sleet': 13, 'heavy intensity rain': 14, 'shower rain': 15, 'thunderstorm': 16, 'thunderstorm with rain': 17, 'drizzle': 18, 'rain and drizzle': 19, 'proximity thunderstorm': 20, 'proximity shower rain': 21, 'sleet': 22, 'light snow': 23, 'snow': 24, 'shower snow': 25, 'smoke': 26, 'haze': 27, 'very heavy rain': 28}\n"
     ]
    }
   ],
   "source": [
    "# transfer weather_description\n",
    "\n",
    "weather_description_unique = list(data[\"weather_description\"].unique())\n",
    "weather_description_map = dict()\n",
    "for i in range(len(weather_description_unique)):\n",
    "    weather_description_map[weather_description_unique[i]] = i\n",
    "print(weather_description_map)\n",
    "keys = []\n",
    "vals = []\n",
    "for key, val in weather_description_map.items():\n",
    "    keys.append(key)\n",
    "    vals.append(val)\n",
    "data[\"weather_description\"] = data[\"weather_description\"].replace(keys, vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10n': 0, '04n': 1, '03n': 2, '02n': 3, '02d': 4, '03d': 5, '04d': 6, '09n': 7, '50d': 8, '09d': 9, '10d': 10, '13n': 11, '01n': 12, '50n': 13, '01d': 14, '13d': 15, '11d': 16}\n"
     ]
    }
   ],
   "source": [
    "# transfer weather_icon\n",
    "weather_icon_unique = list(data[\"weather_icon\"].unique())\n",
    "weather_icon_map = dict()\n",
    "for i in range(len(weather_icon_unique)):\n",
    "    weather_icon_map[weather_icon_unique[i]] = i\n",
    "print(weather_icon_map)\n",
    "keys = []\n",
    "vals = []\n",
    "for key, val in weather_icon_map.items():\n",
    "    keys.append(key)\n",
    "    vals.append(val)\n",
    "data[\"weather_icon\"] = data[\"weather_icon\"].replace(keys, vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# dt_iso delete the +0000 UTC and transfer to datetype\n",
    "data[\"dt_iso\"] = data[\"dt_iso\"].str[: 19]\n",
    "data[\"dt_iso\"] = pd.to_datetime(data[\"dt_iso\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8e3695142d8d70cc076dff4fbe963d409939dbc9737a7401d4845270554ef423"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
